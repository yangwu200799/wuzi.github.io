---
layout: post
title:  "异步处理模型1"
date:   2016-10-26 21:49:23
category: blog
description: 让你的服务异步起来！
---



# 同步、异步

关于同步和异步的概念，相信程序员都不陌生，大家都对其有自己的理解。个人觉得这两个概念会伴随程序员的一生，是计算机技术里面最为重要的概念之一。每个人对其的理解和感悟千差万别。而我的个人理解是（用张三买煎饼作为比喻）

**同步：**

张三到煎饼摊买煎饼，告诉卖煎饼果子的大妈给他做一个煎饼，大妈做煎饼需要一段时间，而这段时间张三一直在等着大妈做完煎饼给他。

**异步：**

张三到煎饼摊买煎饼，告诉卖煎饼果子的大妈给他做一个煎饼，大妈做煎饼需要一段时间，张三不愿意一直等着大妈做完煎饼，所以他就把自己的手机号给了大妈，让大妈做完煎饼给他打个电话震他一下，他再来取，而大妈做煎饼这段时间，张三又去买了牛奶和蛋糕。



上面的例子不是特别恰当，但是能够说明同步和异步的概念。大家明显会感觉到，对于张三来说，异步买煎饼的方式要比同步的方式效率高很多，因为他充分的利用了等待做煎饼的时间来做了其他事情。

对于计算机来说道理是相通的。一个线程，在处理某个请求或者处理某件事情的时候，两种方式差异也是巨大的。如果，处理这件事情使用同步的方式，那么会使得当前线程会阻塞等待这件事情处理完毕，得到结果，这个线程才能继续处理其他事情。如果，处理这件事情使用异步的方式，当等待这件事情正在处理的过程中，这个线程可以用来做其他事情，当这件事情做完的时候再来通知他事情已经完成，通知可以使用回调等方式。

可以看到，异步对于cpu的利用率来说会比同步高很多，在处理事情的效率上也会高很多（提高服务端程序的并发）。可能做过服务端的同学都知道，在某些情况下，**同步也有可能达到跟异步相同的并发，为什么这么说呢**。

举个例子，我们要做的服务端是一个proxy，proxy会接收并向下游转发请求，不过在向下游转发请求之前，需要到一个其他服务获取中间结果，proxy到该中间服务是网络调用，如果一次获取中间结果的耗时需要100ms（很多公司的服务是部署在不同机房的，很多服务之间的网络调用需要跨越地域和机房，本来处理很快的服务加上网络传输的时延在100ms左右是常有的情况）。如果proxy在调用中间服务的方式，如果使用的是异步的方式，proxy不需要很多的处理线程就能够达到1000的并发。

如果使用同步的调用模型，想要达到1000的并发，那么粗略计算，proxy需要的处理线程数是：

1000/(1s/100ms)=100

往往如果希望利用同步的方式达到异步的并发，需要的并行处理的线程数就会非常大，而线程特别多的情况下，会使得线程切换的开销增大，往往不会达到很好的效果。

那么，服务端最优雅、最有效的方式就是使用异步的方式，能用异步尽量少用同步。



# 一种异步处理的服务端框架

对于proxy的一种需求，假如proxy处理一次请求的过程中需要访问10个第三方服务，这10个服务的访问没有顺序的依赖关系，但是将请求转发给下游服务之前需要拿到这10个服务的访问结果，亦即需要等到这10个访问最慢的一个访问完成才可以转发给下游，大家能够想到的实现方式有哪些呢？

下面给出两种实现方式

### 同步的条件量方式：

#### service_impl.cpp

```c++
void ServiceImpl::rpc_method(
	::google::protobuf::RpcController* controller,
	::google::protobuf::Message* request,
	::google::protobuf::Message* response,
	::google::protobuf::Closure* done) {

	TestTask* task = NULL;
  	ThreadEvent* thread_event = NULL;
  	std::vector<ThreadEvent*> thread_event_vec;
  
	for (int i = 0; i < 10; ++i) {
     	thread_event = new ThreadEvent();
      	thread_event_vec.push_back(thread_event);
      
      	task = new TestTask(i);
     	ThreadPool::instance()->add_task();
	}
  
  	// 等待所有task执行完成
  	for (std::vector<ThreadEvent*>::iterator it = thread_event_vec.begin();
         	it != thread_event_vec.end(); ++it) {
    	thread_event = *it;
      	if (thread_event) {
        	thread_event->wait();
          
          	// 释放thread event指针
          	delete thread_event;
          	thread_event = NULL;
          	*it = NULL;
        }
    }
  
  	// 通知上层请求处理完毕
  	done->Run();
} 
```

其中，ThreadEvent是对条件量的封装。

---

### 异步处理模型：

目前很多公司都在使用Google的protobuf作为通信的序列化协议，protobuf中提供了rpc的模型，rpc的调用有同步和异步两种方式，我们充分利用了rpc异步调用的方式，开发的一种通用的异步处理模型。

#### trace_barrier.h

```c++
#include "google/protobuf/stubs/common.h"

class TraceBarrier : public ::google::protobuf::Closure {
public:
    virtual ~TraceBarrier();
    virtual void Run();

private:
    friend TraceBarrier* NewTraceBarrier(size_t left, ::google::protobuf::Closure* done);

    TraceBarrier(size_t left, ::google::protobuf::Closure* done);

    size_t _left;
    ::google::protobuf::Closure* _all_done;
    ThreadMutex _mutex;
};

inline TraceBarrier* NewTraceBarrier(size_t left, ::google::protobuf::Closure* done) {
    if (left > 0 && done != NULL) {
        return new TraceBarrier(left, done);
    }

    if (done) {
        done->Run();
        return NULL;
    }

    CWARNING_LOG("NewTraceBarrier error");
    return NULL;
}

class TraceBarrierHelper {
public:
    TraceBarrierHelper(TraceBarrier* barrier) : _barrier(barrier) {}

    ~TraceBarrierHelper() {
        if (_barrier) {
            _barrier->Run();
        }
    }

private:
    TraceBarrier* _barrier;
};
```



#### trace_barrier.cpp

```c++
#include "trace_barrier.h"

TraceBarrier::~TraceBarrier() {
    if (_left > 0) {
        delete _all_done;
    }

    _all_done = NULL;
}

void TraceBarrier::Run() {
    size_t local_counter = 0;
    {
        ThreadLock lock(_mutex);
        _left--;
        local_counter = _left;
    }

    // 最后一个任务完成了
    if (local_counter == 0) {
        _all_done->Run(); 
        delete this;
    }
}

TraceBarrier::TraceBarrier(size_t left, ::google::protobuf::Closure* done) :
    _left(left), _all_done(done) {

}
```



有了上面的TraceBarrier类，就可以开始我们的异步之旅了，我们可以使用这个异步的处理框架。示例代码如下：



#### service_impl.cpp

```c++
void ServiceImpl::rpc_method(
	::google::protobuf::RpcController* controller,
	::google::protobuf::Message* request,
	::google::protobuf::Message* response,
	::google::protobuf::Closure* done) {
  TraceBarrier* barrier = NewTraceBarrier(
        10, google::protobuf::NewCallback(&callback, request, response, done));

	if (barrier == NULL) {
		return;
	}

	TestTask* task = NULL;
	for (int i = 0; i < 10; ++i) {
     	task = new TestTask(i, barrier);
     	ThreadPool::instance()->add_task();
	}
} 

static void callback(
        ::google::protobuf::Message* request,
        ::google::protobuf::Message* response,
        ::google::protobuf::Closure* done) {
    // 在callback被调用时，说明所有第三方服务调用完成，做其他相应处理 如转发给下游等等

    // 通知上层请求处理完毕
    if (done != NULL) {
        done->Run();
    }
}
```



#### test_task.h

```c++
#include "trace_barrier.h"

class TestTask {
public:
    TestTask(int index, TraceBarrier* barrier) : _index(index), _barrier(barrier) {}
    ~TestTask();

    void execute();

private:
    int _index;
  	TraceBarrier* _barrier;
};
```



#### test_task.cpp

```c++
void TestTask::execute() {
    // 任务完成后调用_barrier->Run()，通知上层
    TraceBarrierHelper barrier_helper(_barrier);

    // 根据_index调用第三方服务
}
```



将10个调用第三方服务的任务放在线程池中处理，是异步处理方式，在rpc_method中将task扔到线程池中，rpc_method就返回，这样rpc_method所在的rpc 服务端work线程就不会被阻塞，线程还能处理其他更多的请求，是一种高效的异步方式。当10个访问第三方服务的任务全部完成，则回调callback函数，在callback函数中调用done->Run()方法，来返回给rpc_method的调用方请求结果，则本次调用rpc_method完毕。



对比同步的方式，大家可以看到，从rpc_method方法接收到请求，并不是直接在rpc_method方法所在的线程中直接去同步等待，而是直接让调用返回，不阻塞rpc worker线程，使用异步的框架，当最后一次调用完成的时候，callback会被回调，而callback中调用done->Run()，给上层返回调用结果。

这样，就完成了异步的服务开发，本文只是提供一种异步的服务端编程思想，抛砖引玉。异步的编程思想可以给我们的程序带来巨大的性能提升，让我们开启异步的变成之旅吧！^-^